{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8yNqkqowBTj"
      },
      "source": [
        "# Training a Text Classifier using LSTM (IMDB Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d62nMawwwAJw"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T48ipyOKwOaT"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TGGm5W4wT2a",
        "outputId": "cab19c39-c026-47eb-f198-14667ce425a6"
      },
      "source": [
        "#Preprocessing the Data\r\n",
        "words=20000\r\n",
        "max_length=100\r\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=words)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHxojmk8whhw"
      },
      "source": [
        "# Text Padding\r\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_length)\r\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_length)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR37xu4wwqj_",
        "outputId": "0839f0d5-a42d-4788-924e-bdd03adc466f"
      },
      "source": [
        "word_size=words\r\n",
        "word_size"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hne3pzwxwwvs"
      },
      "source": [
        "imdb_model=tf.keras.Sequential() #Building a Recurrent Neural Network\r\n",
        "imdb_model.add(tf.keras.layers.Embedding(word_size, 128, input_shape=(x_train.shape[1],))) # Embedding Layer\r\n",
        "imdb_model.add(tf.keras.layers.LSTM(units=128, activation='tanh')) # LSTM Layer\r\n",
        "imdb_model.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # Output Layer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqQbCJd9xDOb",
        "outputId": "6086c5c0-05ff-40fb-f34f-d9991ca2afce"
      },
      "source": [
        "imdb_model.summary() #Summarizing "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FLk7TTAxELb"
      },
      "source": [
        "imdb_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) # Compiling the model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpGcDr2DxIXI",
        "outputId": "700acfd4-91ea-437f-b47b-28b8854f16e5"
      },
      "source": [
        "# Training and Evaluating the Model\r\n",
        "imdb_model.fit(x_train, y_train, epochs=5, batch_size=128)\r\n",
        "\r\n",
        "test_loss, test_acurracy = imdb_model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "print(\"Test accuracy: {}\".format(test_acurracy))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "196/196 [==============================] - 62s 307ms/step - loss: 0.5581 - accuracy: 0.7111\n",
            "Epoch 2/5\n",
            "196/196 [==============================] - 60s 306ms/step - loss: 0.2887 - accuracy: 0.8881\n",
            "Epoch 3/5\n",
            "196/196 [==============================] - 60s 308ms/step - loss: 0.2202 - accuracy: 0.9160\n",
            "Epoch 4/5\n",
            "196/196 [==============================] - 60s 308ms/step - loss: 0.1818 - accuracy: 0.9299\n",
            "Epoch 5/5\n",
            "196/196 [==============================] - 60s 307ms/step - loss: 0.1436 - accuracy: 0.9498\n",
            "782/782 [==============================] - 18s 22ms/step - loss: 0.3938 - accuracy: 0.8315\n",
            "Test accuracy: 0.8314800262451172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yELZbQr3zfMN"
      },
      "source": [
        " # **Thank you!**"
      ]
    }
  ]
}